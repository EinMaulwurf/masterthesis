---
title: "Immo Daten aufbereiten"
format: html
---

# Setup

```{r}
#| message: false
#| warning: false

library(tidyverse)
library(vroom)
library(arrow)
```

# Import
Ich habe zuerst die verschiedenen .csv Dateien in eine Datei zusammengefasst:

```{bash}
#| eval: false

# Header von erster Datei in neue Datei `combined` schreiben
head -n 1 WMSUF1.csv > combined
for f in *.csv; do tail -n +2 "$f" >> combined; done
# Eventuell ist folgende Methode schneller:
# awk 'FNR>1' *.csv >> combined.csv
# Getestet habe ich es nicht.
```

# Kauf

Problem: In den Daten ab 2019 sind die `dupID_gen` komisch. Z.B. `Other missing,Other missing,Other missing,Other missing,Other missing,Other missing,Real-estate agent ,Other missing,1,8794233,"ID occurs once only, or first occurence of ID"` oder `Other missing,Other missing,Other missing,Other missing,Other missing,Other missing,Real-estate agent ,Other missing,2,8307328,Probably one spell`.

Vorest bereinige ich es daher nicht.

```{r}
vroom_col_kauf <- cols_only(
  obid = col_character(),
  gkz = col_character(),
  plz = col_character(),
  kaufpreis = col_double(),
  baujahr = col_integer(),
  wohnflaeche = col_double(),
  zimmeranzahl = col_double(),
  ajahr = col_integer(),
  amonat = col_integer(),
  jahr = col_integer(),
  emonat = col_integer(),
  r1_id = col_character(),
  dupID_gen = col_character()
)

good_dupIDs <- c("ID occurs once only, or first occurence of ID", "Large differences in important features", "Like (4) but time gape >6 months", "Like (1) but time gap >6 months")

import_vroom_kauf <- vroom("./Daten/Immo/Rohdaten/Kauf/combined", col_types = vroom_col_kauf)

import_vroom_kauf_clean <- import_vroom_kauf %>%
  filter(!r1_id %in% c("-11", "-9")) %>%
  #filter(dupID_gen %in% good_dupIDs) %>%
  select(-dupID_gen) %>%
  drop_na(kaufpreis) %>%
  filter(kaufpreis %>% between(., quantile(., 0.01), quantile(., 0.99))) %>%
  mutate(baujahr = na_if(baujahr, -1)) %>%
  rename(ejahr = jahr) %>%
  mutate(x_mp = r1_id %>% str_extract("^\\d{4}") %>% as.numeric(),
         y_mp = r1_id %>% str_extract("\\d{4}$") %>% as.numeric(),
         x_mp = x_mp * 1000 + 500,
         y_mp = y_mp * 1000 + 500)

import_vroom_kauf_clean %>%
  group_by(ejahr) %>%
  write_dataset("./Daten/Immo/Kauf/")
```

```{r}
open_dataset("./Daten/Immo/Kauf/") %>%
  group_by(ejahr) %>%
  count() %>%
  collect()
```


# Miete

Gleiches Problem mit `dupID_gen` wie oben. Vorest bereinige ich es daher nicht.

```{r}
vroom_col_miete <- cols_only(
  obid = col_character(),
  gkz = col_character(),
  plz = col_character(),
  mietekalt = col_double(),
  baujahr = col_integer(),
  wohnflaeche = col_double(),
  zimmeranzahl = col_double(),
  ajahr = col_integer(),
  amonat = col_integer(),
  jahr = col_integer(),
  emonat = col_integer(),
  r1_id = col_character(),
  dupID_gen = col_character()
)

good_dupIDs <- c("ID occurs once only, or first occurence of ID", "Large differences in important features", "Like (4) but time gape >6 months", "Like (1) but time gap >6 months")

import_vroom_miete <- vroom("./Daten/Immo/Rohdaten/Miete/combined", col_types = vroom_col_miete)

import_vroom_miete_clean <- import_vroom_miete %>%
  filter(!r1_id %in% c("-11", "-9")) %>%
  #filter(dupID_gen %in% good_dupIDs) %>%
  select(-dupID_gen) %>%
  drop_na(mietekalt) %>%
  drop_na(wohnflaeche) %>%
  filter(mietekalt %>% between(., quantile(., 0.01), quantile(., 0.99))) %>%
  filter(wohnflaeche %>% between(., quantile(., 0.01), quantile(., 0.99))) %>%
  mutate(baujahr = na_if(baujahr, -1)) %>%
  rename(ejahr = jahr) %>%
  mutate(x_mp = r1_id %>% str_extract("^\\d{4}") %>% as.numeric(),
         y_mp = r1_id %>% str_extract("\\d{4}$") %>% as.numeric(),
         x_mp = x_mp * 1000 + 500,
         y_mp = y_mp * 1000 + 500)

import_vroom_miete_clean %>%
  group_by(ejahr) %>%
  write_dataset("./Daten/Immo/Miete/")
```

Achtung: bei `import_vroom_miete_clean` sind nur Daten bis 2019. Irgendwie werden also spätere Anzeigen alle rausgefiltert. Möglicherweise wegen der `dupID_gen`.

```{r}
import_vroom_miete_clean_test <- import_vroom_miete %>%
  filter(!r1_id %in% c("-11", "-9")) %>%
  #filter(dupID_gen %in% good_dupIDs) %>%
  #select(-dupID_gen) %>%
  drop_na(mietekalt) %>%
  drop_na(wohnflaeche) %>%
  filter(mietekalt %>% between(., quantile(., 0.01), quantile(., 0.99))) %>%
  filter(wohnflaeche %>% between(., quantile(., 0.01), quantile(., 0.99))) %>%
  mutate(baujahr = na_if(baujahr, -1)) %>%
  rename(ejahr = jahr) %>%
  mutate(x_mp = r1_id %>% str_extract("^\\d{4}") %>% as.numeric(),
         y_mp = r1_id %>% str_extract("\\d{4}$") %>% as.numeric(),
         x_mp = x_mp * 1000 + 500,
         y_mp = y_mp * 1000 + 500)

import_vroom_miete_clean_test %>%
  filter(ejahr > 2019) %>%
  count(dupID_gen)
```

```{r}
open_dataset("./Daten/Immo/Miete/") %>%
  group_by(ejahr) %>%
  count() %>%
  collect()
```

# RWI GEO REDX PUF

HK = House sales, WK = Apartment sales, WM = Apartment rents, CI = Combined Index

```{r}
rwi_geo_redx_puf <- readxl::read_xlsx("./Daten/RWI_GEO_REDX_PUF/RWIGEOREDX_GRIDS_v13_PUF.xlsx",
                          sheet = "Grids_RegionEff_yearly") %>%
  pivot_longer(
    cols = starts_with(c("pindex", "NOBS")),
    names_to = c(".value", "year"),
    names_pattern = "(pindex|NOBS)(\\d{4})"
  ) %>%
  rename(nobs = NOBS) %>%
  mutate(x_mp = grid %>% str_extract("^\\d{4}") %>% as.numeric(),
         y_mp = grid %>% str_extract("\\d{4}$") %>% as.numeric(),
         x_mp = x_mp * 1000 + 500,
         y_mp = y_mp * 1000 + 500,
         .keep = "unused",
         .before = 1) %>%
  pivot_wider(names_from = housing_type, values_from = c(pindex, nobs)) %>%
  mutate(year = as.numeric(year))

rwi_geo_redx_puf %>%
  write_parquet("./Daten/RWI_GEO_REDX_PUF/rwi_geo_redx_puf.parquet")
```

```{r}
rwi_geo_redx_puf %>%
  inner_join(
    cells_gemeinden_bbsr %>%
      filter(gemeindetyp_differenziert_name == "Größere Großstadt")
  ) %>%
  filter(year >= 2018)
```

# RWI GEO RED aggregieren

Definieren von Pseudo-Daten (halbjährlich). Von der `did` Funktion werden Zeitpunkte benötigt. Jahre wäre zu grob, Monate wahrscheinlich zu fein. Ein guter Kompromiss sind daher halbjahre. Diese stimmen dann auch mit den Breitband Meldungen überein.

Ich fange bei 2017 an, dann gibt es einen gewissen Zeitraum, um Pretrends zu testen.

```{r}
min_date <- 201601
max_date <- 202406

dates_pseudo_halbjahr <- tibble(date = seq(
  from = ym(min_date),
  to = ym(max_date),
  by = "1 month"
)) %>%
  mutate(date = as.numeric(format(date, "%Y%m"))) %>%
  left_join(
    tibble(date = seq(
      from = ym(min_date),
      to = ym(max_date),
      by = "6 months"
      )) %>%
      mutate(date = as.numeric(format(date, "%Y%m")), 
             date_pseudo_halbjahr = seq_along(date)),
    by = join_by(date)
    ) %>%
  fill(date_pseudo_halbjahr, .direction = "down")
```

```{r}
got_fiber_dates <- read_parquet("./Daten/Breitbandatlas//Raster_1km_got_fiber_date.parquet") %>%
  left_join(dates_pseudo_halbjahr, by = join_by(got_fiber_date == date)) %>%
  rename(got_fiber_date_pseudo_halbjahr = date_pseudo_halbjahr)

cells_gemeinden_bbsr <- read_parquet("./Daten/Raumgliederung_BBSR/Raster_1km_gemeinden_bbsr.parquet")

breitband_problems <- read_parquet("./Daten/Breitbandatlas/Raster_1km_problems.parquet")
```

## Kauf

Hier werden die Kauf-Daten zu einem Index auf Rasterebene aggregiert. Im Idealfall gibt es pro Zelle für jede Zeitperiode (halbes Jahr) genügend Beobachtungen, aus denen dann der Mittelwert bestimmt wird. Dies ist jedoch für viele Zellen (in ländlicheren Gegenden) nicht der Fall. Daher erstelle ich mit `tidyr::complete()` zuerst alle Kombinationen aus den Zeitperioden und Zellen. Anschließend werden die fehlenden Daten mit `tidyr::fill()` aufgefüllt.

Code unten sollte noch angepasst werden, ist aktuell nur rüberkopiert aus dem `did.qmd` file.
Insbesondere an dem `fill()` sollte man nochmal arbeiten. Hier wird aktuell eher zu viel/großzügig ausgefüllt. Vielleicht könnte man auch noch eine neue Spalte pro Zelle machen, die anzeigt wie viele Halbjahre es mit Beobachtungen gibt.

Der `anti_join(breitband_problems, by = join_by(x_mp, y_mp))` Teil ist dafür da, um problematische Zellen rauszuwerfen. Das sind solche Zellen, in denen der Glasfaserausbau in mindestens einer Periode sinkt. Blöd ist aber, dass es über 12000 Zellen von etwa 45000 Zellen insgesamt ist. Das ist ein sehr großer Anteil an nicht mehr verwendbaren Daten.

```{r}
data_kauf <- open_dataset("./Daten/Immo/Kauf/") %>%
  filter(ejahr >= 2016) %>%
  mutate(date = ejahr*100 + emonat) %>%
  select(date, x_mp, y_mp, kaufpreis, baujahr, wohnflaeche, zimmeranzahl) %>%
  collect() %>%
  left_join(dates_pseudo_halbjahr, by = join_by(date)) %>%
  select(date_pseudo_halbjahr, x_mp, y_mp, kaufpreis, baujahr, wohnflaeche, zimmeranzahl)

data_kauf_complete <- data_kauf %>%
  group_by(date_pseudo_halbjahr, x_mp, y_mp) %>%
  summarise(mean_kaufpreis = mean(kaufpreis, na.rm = TRUE),
            n_cell_date = n(),
            median_baujahr = median(baujahr, na.rm = TRUE),
            median_wohnflaeche = median(wohnflaeche, na.rm = TRUE),
            median_zimmeranzahl = median(zimmeranzahl, na.rm = TRUE),
            .groups = "drop") %>%
  arrange(x_mp, y_mp, date_pseudo_halbjahr) %>%
  group_by(x_mp, y_mp) %>%
  mutate(n_cell = sum(n_cell_date)) %>%
  ungroup() %>%
  mutate(xy_mp = (x_mp-500)*10 + (y_mp-500)/1000) %>%
  mutate(median_baujahr = if_else(is.na(median_baujahr), 
                           median(median_baujahr, na.rm = TRUE), 
                           median_baujahr)) %>%
  complete(xy_mp, date_pseudo_halbjahr) %>%
  group_by(xy_mp) %>%
  fill(everything(), -n_cell_date, .direction = "downup") %>%
  ungroup() %>%
  mutate(n_cell_date = replace_na(n_cell_date, 0)) %>%
  left_join(cells_gemeinden_bbsr %>% select(x_mp, y_mp, ends_with("_name")), by = join_by(x_mp, y_mp)) %>%
  left_join(got_fiber_dates, by = join_by(x_mp, y_mp)) %>%
  mutate(got_fiber_date = replace_na(got_fiber_date, 0))# %>%
  #anti_join(breitband_problems, by = join_by(x_mp, y_mp))

write_parquet(data_kauf_complete, "./Daten/data_kauf_complete.parquet")
```

```{r}
data_kauf_missing <- data_kauf_complete %>%
  select(x_mp, y_mp, n_cell_date) %>%
  group_by(x_mp, y_mp) %>%
  summarise(
    has_missing = any(n_cell_date == 0),
    missing_count = sum(n_cell_date == 0),
    .groups = "drop"
  ) %>%
  filter(has_missing) %>%
  select(x_mp, y_mp, missing_count)

data_kauf_missing %>% pull(missing_count) %>% quantile()
```

```{r}
top_cells <- data_kauf_complete %>%
  arrange(desc(n_cell)) %>%
  distinct(xy_mp, n_cell) %>%
  head(1000) %>%
  pull(xy_mp)

data_kauf_complete %>%
  #filter(xy_mp == "45543277") %>%
  filter(xy_mp %in% top_cells) %>%
  ggplot(aes(x = date_pseudo_halbjahr, y = mean_kaufpreis, group = as.factor(xy_mp)))+
  geom_line(alpha = .1)+
  scale_y_log10()+
  scale_x_continuous(breaks = 0:16)

data_kauf_complete %>%
  arrange(desc(n_cell)) %>%
  distinct(xy_mp, n_cell) %>%
  head(10) %>%
  pull(xy_mp)
```

## Miete

```{r}
data_miete <- open_dataset("./Daten/Immo/Miete/") %>%
  filter(ejahr >= 2016) %>%
  mutate(date = ejahr*100 + emonat) %>%
  mutate(mietekalt_m2 = mietekalt / wohnflaeche) %>%
  select(date, x_mp, y_mp, mietekalt_m2, baujahr, wohnflaeche, zimmeranzahl) %>%
  collect() %>%
  left_join(dates_pseudo_halbjahr, by = join_by(date)) %>%
  select(date_pseudo_halbjahr, x_mp, y_mp, mietekalt_m2, baujahr, wohnflaeche, zimmeranzahl)

data_miete_complete <- data_miete %>%
  group_by(date_pseudo_halbjahr, x_mp, y_mp) %>%
  summarise(mean_mietekalt_m2 = mean(mietekalt_m2, na.rm = TRUE),
            n_cell_date = n(),
            median_baujahr = median(baujahr, na.rm = TRUE),
            median_wohnflaeche = median(wohnflaeche, na.rm = TRUE),
            median_zimmeranzahl = median(zimmeranzahl, na.rm = TRUE),
            .groups = "drop") %>%
  arrange(x_mp, y_mp, date_pseudo_halbjahr) %>%
  group_by(x_mp, y_mp) %>%
  mutate(n_cell = sum(n_cell_date)) %>%
  ungroup() %>%
  mutate(xy_mp = (x_mp-500)*10 + (y_mp-500)/1000) %>%
  mutate(median_baujahr = if_else(is.na(median_baujahr), 
                           median(median_baujahr, na.rm = TRUE), 
                           median_baujahr)) %>%
  complete(xy_mp, date_pseudo_halbjahr) %>%
  group_by(xy_mp) %>%
  fill(everything(), -n_cell_date, .direction = "downup") %>%
  ungroup() %>%
  mutate(n_cell_date = replace_na(n_cell_date, 0)) %>%
  left_join(cells_gemeinden_bbsr %>% select(x_mp, y_mp, ends_with("_name")), by = join_by(x_mp, y_mp)) %>%
  left_join(got_fiber_dates, by = join_by(x_mp, y_mp)) %>%
  mutate(got_fiber_date_pseudo_halbjahr = replace_na(got_fiber_date_pseudo_halbjahr, 0))# %>%
  #anti_join(breitband_problems, by = join_by(x_mp, y_mp))

write_parquet(data_miete_complete, "./Daten/data_miete_complete.parquet")
```

